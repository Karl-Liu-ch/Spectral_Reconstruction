{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import cv2\n",
    "from spectral import *\n",
    "from utils import Loss_Fid, Loss_SAM, Loss_SSIM, reconRGB, bgr2rgb\n",
    "import hyperspy.api as hs\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "ROOT = '/work3/s212645/Spectral_Reconstruction'\n",
    "\n",
    "TRAIN_RGB = '/Train_RGB/'\n",
    "TRAIN_SP = '/Valid_Spec/'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import re\n",
    "\n",
    "spec = '/work3/s212645/Spectral_Reconstruction/CAVE/'\n",
    "\n",
    "def Rename(spec):\n",
    "    filelist = os.listdir(spec)\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    for file in filelist:\n",
    "        if re.findall(reg, file):\n",
    "            oldname = spec + file\n",
    "            number = file.split('.mat')[0]\n",
    "            newnumber = number.zfill(3)\n",
    "            newname = spec + newnumber + '.mat'\n",
    "            os.rename(oldname, newname)\n",
    "\n",
    "filelist = os.listdir(spec)\n",
    "filelist.sort()\n",
    "reg = re.compile(r'.*.mat')\n",
    "for file in filelist:\n",
    "    if re.match(reg, file):\n",
    "        mat = scipy.io.loadmat(spec+file)\n",
    "        hyper = np.float32(np.array(mat['cube']))\n",
    "        rgb = np.float32(np.array(mat['rgb']))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "class Loss_Fid(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fid = FrechetInceptionDistance(feature=2048)\n",
    "        \n",
    "    def forward(self, outputs, label):\n",
    "        outputs = outputs * 255\n",
    "        label = label * 255\n",
    "        outputs = outputs.type(torch.ByteTensor)\n",
    "        label = label.type(torch.ByteTensor)\n",
    "        self.fid.update(label, real=True)\n",
    "        self.fid.update(outputs, real=False)\n",
    "        fidscore = self.fid.compute()\n",
    "        return fidscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(spec, 'r') as mat:\n",
    "    hyper =np.float32(np.array(mat['cube']))\n",
    "hyper = np.transpose(hyper, [2, 1, 0])\n",
    "subhyper = cv2.resize(hyper, [128, 128])\n",
    "print(subhyper.shape)\n",
    "rgb = get_rgb(subhyper, (29, 19, 9)) # fid score\n",
    "plt.imshow(rgb)\n",
    "# indices = [22, 12, 3]\n",
    "# subhyper = hyper[indices]\n",
    "# subhyper = np.transpose(subhyper, [2, 1, 0])\n",
    "# subhyper = cv2.cvtColor(subhyper, cv2.COLOR_BGR2RGB)\n",
    "# subhyper = np.float32(subhyper)\n",
    "# subhyper = (subhyper-subhyper.min())/(subhyper.max()-subhyper.min())\n",
    "# plt.imshow(subhyper)\n",
    "# view = ImageView()\n",
    "# view.set_data(hyper, (29, 19, 9)) # fid score\n",
    "# # view.set_data(hyper, (20, 13, 9)) # sam\n",
    "# plt.imshow(view.data_rgb)\n",
    "# subhyper = torch.tensor(view.data_rgb.transpose(2, 0, 1), dtype=torch.float32).to(device)\n",
    "# sam = Loss_SAM().to(device)\n",
    "# fid = Loss_Fid().to(device)\n",
    "# lossmin = 1e12\n",
    "# argi = 0\n",
    "# argj = 1\n",
    "# argk = 2\n",
    "\n",
    "# loss = fid(bgr.reshape(8, 3, 482 // 2, 512 // 4), subhyper.reshape(8, 3, 482 // 2, 512 // 4))\n",
    "# # print(subhyper)\n",
    "# for i in range(0,10):\n",
    "#     for j in range(10,20):\n",
    "#         for k in range(20, 31):\n",
    "#             view.set_data(hyper, (k, j, i))\n",
    "#             subhyper = torch.tensor(view.data_rgb.transpose(2, 0, 1), dtype=torch.float32).to(device)\n",
    "#             loss = fid(bgr.reshape(8, 3, 482 // 2, 512 // 4), subhyper.reshape(8, 3, 482 // 2, 512 // 4))\n",
    "#             if loss < lossmin:\n",
    "#                 lossmin = loss\n",
    "#                 argi = i\n",
    "#                 argj = j\n",
    "#                 argk = k\n",
    "#                 print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/work3/s212645/Spectral_Reconstruction/ICVL/data/mat/4cam_0411-1640-1.mat'\n",
    "with h5py.File(path, 'r') as mat:\n",
    "    hyper = np.float32(np.array(mat['rad']))\n",
    "    rgb = np.float32(np.array(mat['rgb']))\n",
    "hyper = np.transpose(hyper, [1, 2, 0])\n",
    "hyper = np.flip(hyper, 0)\n",
    "rgb = np.transpose(rgb, [2, 1, 0])\n",
    "rgb = np.flip(rgb, 2)\n",
    "# view = ImageView()\n",
    "rgb = get_rgb(hyper, (29, 19, 9)) # fid score\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for path, dirs, files in os.walk(ROOT+TRAIN_SP):\n",
    "    for file in files:\n",
    "        num_video = os.path.basename(path)\n",
    "        names.append(os.path.basename(os.path.dirname(path)))\n",
    "        hyper_path = os.path.join(path,file)\n",
    "        with h5py.File(hyper_path, 'r') as mat:\n",
    "            hyper =np.float32(np.array(mat['cube']))\n",
    "        hyper = np.transpose(hyper, [2, 1, 0])\n",
    "        imshow(hyper, (22, 10, 3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for path, dirs, files in os.walk(ROOT+TRAIN_RGB):\n",
    "    for file in files:\n",
    "        num_video = os.path.basename(path)\n",
    "        names.append(os.path.basename(os.path.dirname(path)))\n",
    "        hyper_path = os.path.join(path,file)\n",
    "        bgr_path = os.path.join(path,file)\n",
    "        bgr = cv2.imread(bgr_path)\n",
    "        bgr2rgb = True\n",
    "        if bgr2rgb:\n",
    "            bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        bgr = np.float32(bgr)\n",
    "        bgr = (bgr-bgr.min())/(bgr.max()-bgr.min())\n",
    "        bgr = np.transpose(bgr, [2, 0, 1])  # [3,482,512]\n",
    "        \n",
    "        stride = 8\n",
    "        crop_size = 128\n",
    "        idx = 0\n",
    "        \n",
    "        h,w = 482,512  # img shape\n",
    "        patch_per_line = (w-crop_size)//stride+1\n",
    "        patch_per_colum = (h-crop_size)//stride+1\n",
    "        patch_per_img = patch_per_line*patch_per_colum\n",
    "        img_idx, patch_idx = idx//patch_per_img, idx%patch_per_img\n",
    "        h_idx, w_idx = patch_idx//patch_per_line, patch_idx%patch_per_line\n",
    "        img = bgr[:,h_idx*stride:h_idx*stride+crop_size, w_idx*stride:w_idx*stride+crop_size]\n",
    "        \n",
    "        img = img.transpose(1,2,0)\n",
    "        print(img.shape)\n",
    "        plt.imshow(bgr.transpose(1,2,0))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.randn([64,31,128,128])\n",
    "label = torch.randn_like(outputs)\n",
    "error = torch.abs(outputs.view(-1) - label.view(-1)) / label.view(-1)\n",
    "# mrae = torch.mean(error.reshape(-1))\n",
    "mrae = torch.mean(error.view(-1))\n",
    "mrae\n",
    "a = np.array([0,1,1])\n",
    "print(a.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "recons = torch.randn(1, 31, 128, 128)\n",
    "input = torch.randn_like(recons)\n",
    "mu = torch.randn(1, 1024)\n",
    "log_var = torch.randn_like(mu)\n",
    "\n",
    "kld_weight = 1024 / 128 / 128 / 31 # Account for the minibatch samples from the dataset\n",
    "recons_loss =F.mse_loss(recons, input)\n",
    "\n",
    "kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "print(recons_loss, kld_loss * kld_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "window_size = 4\n",
    "shift_size = 3\n",
    "H, W = 16, 16\n",
    "img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "h_slices = (slice(0, -window_size),\n",
    "            slice(-window_size, -window_size * 2),\n",
    "            slice(-window_size * 2, -window_size * 3),\n",
    "            slice(-window_size * 3, -shift_size),\n",
    "            slice(-shift_size, None))\n",
    "w_slices = (slice(0, -window_size),\n",
    "            slice(-window_size, -window_size * 2),\n",
    "            slice(-window_size * 2, -window_size * 3),\n",
    "            slice(-window_size * 3, -shift_size),\n",
    "            slice(-shift_size, None))\n",
    "cnt = 0\n",
    "for h in h_slices:\n",
    "    for w in w_slices:\n",
    "        img_mask[:, h, w, :] = cnt\n",
    "        cnt += 1\n",
    "\n",
    "mask_windows = window_partition(img_mask, window_size)  # nW, window_size, window_size, 1\n",
    "mask_windows = mask_windows.view(-1, window_size * window_size)\n",
    "\n",
    "attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "plt.matshow(img_mask[0, :, :, 0].numpy())\n",
    "for i in range(16):\n",
    "    plt.matshow(attn_mask[i].numpy())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=159'>160</a>\u001b[0m path \u001b[39m=\u001b[39m root \u001b[39m+\u001b[39m datanames[\u001b[39m2\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39m# spectral_images, rgb_images = get_all_mats(path, 128)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=161'>162</a>\u001b[0m \u001b[39m# print(len(rgb_images))\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39m# print(rgb_images[-1].shape)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m train_sets, test_sets \u001b[39m=\u001b[39m cross_validation_dataset(path, \u001b[39m1\u001b[39;49m, \u001b[39m128\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_sets[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=165'>166</a>\u001b[0m \u001b[39mprint\u001b[39m(sys\u001b[39m.\u001b[39mgetsizeof(train_sets[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]))\n",
      "\u001b[1;32m/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb 单元格 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m num_crossval \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(crossvaltrainlists)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_crossval):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     train_sets\u001b[39m.\u001b[39mappend(get_dataset(crossvaltrainlists[i], imsize))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m     test_sets\u001b[39m.\u001b[39mappend(get_dataset(crossvaltestlists[i], imsize))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mreturn\u001b[39;00m train_sets, test_sets\n",
      "\u001b[1;32m/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb 单元格 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataset\u001b[39m(\u001b[39mlist\u001b[39m, imsize):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     specs, rgbs \u001b[39m=\u001b[39m get_all_mats(\u001b[39mlist\u001b[39;49m, imsize)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m specs, rgbs\n",
      "\u001b[1;32m/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb 单元格 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m rgbs \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m filelist:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     mat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(path\u001b[39m+\u001b[39;49mfile)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m     spec, rgb \u001b[39m=\u001b[39m get_all_patches(mat, imsize)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Blogin1.hpc.dtu.dk/zhome/02/b/164706/Master_Courses/2023_Fall/Spectral_Reconstruction/data_visualization.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m     specs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m spec\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/scipy/io/matlab/_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 227\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39;49mget_variables(variable_names)\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m mdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     mdict\u001b[39m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/scipy/io/matlab/_mio5.py:332\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_var_array(hdr, process)\n\u001b[1;32m    333\u001b[0m \u001b[39mexcept\u001b[39;00m MatReadError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    334\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    335\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mUnreadable variable \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, because \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    336\u001b[0m         (name, err),\n\u001b[1;32m    337\u001b[0m         \u001b[39mWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.11/site-packages/scipy/io/matlab/_mio5.py:292\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_var_array\u001b[39m(\u001b[39mself\u001b[39m, header, process\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m''' Read array, given `header`\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[1;32m    278\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m       `process`.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matrix_reader\u001b[39m.\u001b[39;49marray_from_header(header, process)\n",
      "File \u001b[0;32m_mio5_utils.pyx:666\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:695\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:769\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_real_complex\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:446\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_numeric\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:351\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_element\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_streams.pyx:170\u001b[0m, in \u001b[0;36mscipy.io.matlab._streams.ZlibInputStream.read_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pyalloc.pxd:9\u001b[0m, in \u001b[0;36mscipy.io.matlab._pyalloc.pyalloc_v\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from options import opt\n",
    "import scipy.io\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = '/work3/s212645/Spectral_Reconstruction/'\n",
    "datanames = ['ICVL/', 'ARAD/', 'CAVE/']\n",
    "\n",
    "def Rename(path):\n",
    "    filelist = os.listdir(path)\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    for file in filelist:\n",
    "        if re.findall(reg, file):\n",
    "            oldname = path + file\n",
    "            number = file.split('.mat')[0]\n",
    "            newnumber = number.zfill(3)\n",
    "            newname = path + newnumber + '.mat'\n",
    "            os.rename(oldname, newname)\n",
    "\n",
    "def gen_test_list(matlist, startidx, size):\n",
    "    testlist = []\n",
    "    for i in range(size):\n",
    "        testlist.append(matlist[i + startidx])\n",
    "    return testlist\n",
    "\n",
    "def cross_validation_lists(path, test_size):\n",
    "    crossvaltrainlists = []\n",
    "    crossvaltestlists = []\n",
    "    filelist = os.listdir(path)\n",
    "    filelist.sort()\n",
    "    assert len(filelist) > test_size\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    matlist = []\n",
    "    for file in filelist:\n",
    "        if re.match(reg, file):\n",
    "            matlist.append(file)\n",
    "    matlist.sort()\n",
    "    all_length = len(matlist)\n",
    "    assert all_length % test_size == 0\n",
    "    for i in range(all_length // test_size):\n",
    "        trainlist = []\n",
    "        testlist = []\n",
    "        testlist = gen_test_list(matlist, i * test_size, test_size)\n",
    "        trainlist = matlist.copy()\n",
    "        for mat in testlist:\n",
    "            trainlist.remove(mat)\n",
    "        crossvaltestlists.append(testlist)\n",
    "        crossvaltrainlists.append(trainlist)\n",
    "    return crossvaltrainlists, crossvaltestlists\n",
    "\n",
    "def cross_validation_dataset(path, test_size, imsize):\n",
    "    train_sets = []\n",
    "    test_sets = []\n",
    "    crossvaltrainlists, crossvaltestlists = cross_validation_lists(path, test_size)\n",
    "    num_crossval = len(crossvaltrainlists)\n",
    "    for i in range(num_crossval):\n",
    "        train_sets.append(get_dataset(crossvaltrainlists[i], imsize))\n",
    "        test_sets.append(get_dataset(crossvaltestlists[i], imsize))\n",
    "    return train_sets, test_sets\n",
    "\n",
    "def get_dataset(list, imsize):\n",
    "    specs, rgbs = get_all_mats(list, imsize)\n",
    "    return specs, rgbs\n",
    "\n",
    "def split_train_test(path, test_size):\n",
    "    filelist = os.listdir(path)\n",
    "    filelist.sort()\n",
    "    assert len(filelist) > test_size\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    matlist = []\n",
    "    for file in filelist:\n",
    "        if re.match(reg, file):\n",
    "            matlist.append(file)\n",
    "    all_length = len(matlist)\n",
    "    train_size = all_length - test_size\n",
    "    matlist.sort()\n",
    "    trainlist = []\n",
    "    testlist = []\n",
    "    for i in range(train_size):\n",
    "        trainlist.append(matlist[i])\n",
    "    for j in range(test_size):\n",
    "        testlist.append(matlist[j + train_size])\n",
    "    return trainlist, testlist\n",
    "\n",
    "def get_all_mats(filelist, imsize):\n",
    "    specs = []\n",
    "    rgbs = []\n",
    "    for file in filelist:\n",
    "        mat = scipy.io.loadmat(path+file)\n",
    "        spec, rgb = get_all_patches(mat, imsize)\n",
    "        specs += spec\n",
    "        rgbs += rgb\n",
    "        # break\n",
    "    return specs, rgbs\n",
    "    \n",
    "def Resize(hyper, rgb, h, w):\n",
    "    hyper_s = cv2.resize(hyper, [h, w])\n",
    "    rgb_s = cv2.resize(rgb, [h, w])\n",
    "    return hyper_s, rgb_s\n",
    "\n",
    "def data_resize(mat, imsize):\n",
    "    spectral_images = []\n",
    "    rgb_images = []\n",
    "    hyper = np.float32(np.array(mat['cube']))\n",
    "    rgb = np.float32(np.array(mat['rgb']))\n",
    "    h = rgb.shape[0]\n",
    "    w = rgb.shape[1]\n",
    "    while min(h // imsize, w // imsize) >= 1:\n",
    "        hyper_s, rgb_s = Resize(hyper, rgb, h, w)\n",
    "        spectral_images.append(hyper_s)\n",
    "        rgb_images.append(rgb_s)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "    if h > imsize / 2 or w > imsize / 2 :\n",
    "        hyper_s, rgb_s = Resize(hyper, rgb, imsize, imsize)\n",
    "        spectral_images.append(hyper_s)\n",
    "        rgb_images.append(rgb_s)\n",
    "    return spectral_images, rgb_images\n",
    "\n",
    "def patch_gen(array, imsize, h, w):\n",
    "    return array[h-imsize:h, w-imsize:w, :]\n",
    "\n",
    "def patch_image(array, imsize):\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "    assert h >= imsize\n",
    "    assert w >= imsize\n",
    "    iter_h = int(np.ceil(h / imsize) + 1)\n",
    "    iter_w = int(np.ceil(w / imsize) + 1)\n",
    "    patches = []\n",
    "    for i in range(1, iter_h):\n",
    "        for j in range(1, iter_w):\n",
    "            patches.append(patch_gen(array, imsize, min(h, i * imsize), min(w, j * imsize)))\n",
    "    return patches\n",
    "    \n",
    "def get_all_patches(mat, imsize):\n",
    "    spectrals = []\n",
    "    rgbs = []\n",
    "    resize_spectrals, resize_rgbs = data_resize(mat, imsize)\n",
    "    for i in range(len(resize_spectrals)):\n",
    "        hyperpatches = patch_image(resize_spectrals[i], imsize)\n",
    "        rgbpatches = patch_image(resize_rgbs[i], imsize)\n",
    "        spectrals += hyperpatches\n",
    "        rgbs += rgbpatches\n",
    "    return spectrals, rgbs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = root + datanames[2]\n",
    "    # spectral_images, rgb_images = get_all_mats(path, 128)\n",
    "    # print(len(rgb_images))\n",
    "    # print(rgb_images[-1].shape)\n",
    "    train_sets, test_sets = cross_validation_dataset(path, 1, 128)\n",
    "    print(len(train_sets[0]))\n",
    "    print(sys.getsizeof(train_sets[0][0]))\n",
    "    imshow(train_sets[0][1][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
