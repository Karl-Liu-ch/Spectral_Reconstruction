{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import cv2\n",
    "from spectral import *\n",
    "from utils import Loss_Fid, Loss_SAM, Loss_SSIM, reconRGB, bgr2rgb\n",
    "import hyperspy.api as hs\n",
    "from visualize import *\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "ROOT = '/work3/s212645/Spectral_Reconstruction/RealHyperSpectrum/'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames = {'CVAE': 'CVAE', \n",
    "                'SNCWGANres': 'SNCWGAN+ResNet', \n",
    "                'pix2pix': 'pix2pix', \n",
    "                'SNCWGANunet': 'SNCWGAN+Unet', \n",
    "                'SNCWGANdense': 'SNCWGAN+DenseNet', \n",
    "                'HSCNN_Plus': 'HSCNN_Plus', \n",
    "                'MSTPlusPlus': 'MST++', \n",
    "                'CVAESP': 'CVAE-HS', \n",
    "                'SNCWGANNoNoise': 'SNCWGAN+DT', \n",
    "                'D2GANNZ': 'D2GAN'}\n",
    "root = '/work3/s212645/Spectral_Reconstruction/FakeHyperSpectrum/'\n",
    "hsis = [5642,5453,5621]\n",
    "for k, v in modelnames.items():\n",
    "    path = root + k + '/'\n",
    "    Dict = {}\n",
    "    Dict[v] = {}\n",
    "    for hsi in hsis:\n",
    "        Dict[v][hsi] = plot_spectral_density(path, hsi)\n",
    "        # visualize_result(v, path, hsi)\n",
    "    modelnames[k] = Dict\n",
    "GT_dict = {}\n",
    "GT_dict['GT'] = {}\n",
    "path = '/work3/s212645/Spectral_Reconstruction/RealHyperSpectrum/'\n",
    "for hsi in hsis:\n",
    "    GT_dict['GT'][hsi] = plot_spectral_density(path, hsi)\n",
    "bands = np.linspace(400,700,31)\n",
    "for hsi in hsis:\n",
    "    lines = []\n",
    "    for k, v in modelnames.items():\n",
    "        for k, v in v.items():\n",
    "            plt.plot(bands, v[hsi])\n",
    "            lines.append(k)\n",
    "\n",
    "    plt.plot(bands, GT_dict['GT'][hsi], color = 'cyan')\n",
    "    lines.append('GT')\n",
    "    plt.legend(labels=lines, loc='best')\n",
    "    plt.title('Spectral Density')\n",
    "    plt.savefig(f'results/{hsi}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/work3/s212645/Spectral_Reconstruction/FakeHyperSpectrum/SNCWGANdense/'\n",
    "hsi = 5642\n",
    "visualize_result('SNCWGAN+DT', root, hsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NTIRE2022Util import load_rgb_filter\n",
    "filter, bands = load_rgb_filter('resources/CIE_xyz_1964_10deg.csv')\n",
    "sample = scipy.io.loadmat(ROOT + '5642.mat')\n",
    "hyper = sample['cube']\n",
    "rgb = sample['rgb']\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "k = 155\n",
    "for i in range(36):\n",
    "    num = str(i+k*36+30).zfill(3)\n",
    "    sample = scipy.io.loadmat(ROOT + num + '.mat')\n",
    "    hyper = sample['cube']\n",
    "    rgb = sample['rgb']\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "images = []\n",
    "for b in range(31):\n",
    "    band = 400 + 10 * b\n",
    "    image = np.zeros([128, 128, 3])\n",
    "    filter[band-360,:]\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            image[i, j, :] = filter[band-360,:] * hyper[i, j, b]\n",
    "    image = (image-image.min()) / (image.max() - image.min())\n",
    "    images.append(image)\n",
    "    plt.subplot(6, 6, b+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "for i in range(31):\n",
    "    ax1 = fig.add_axes([-i * 0.015, -i * 0.015, 1, 1])  # [left, bottom, width, height]\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(images[30-i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "images = []\n",
    "bands = [400, 500, 550, 700]\n",
    "b = 0\n",
    "spectral_density = []\n",
    "images.append(rgb)\n",
    "for band in bands:\n",
    "    image = np.zeros([128, 128, 3])\n",
    "    # 假设 filter 和 hyper 已定义\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            image[i, j, :] = filter[band-360, :] * hyper[i, j, b]\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    images.append(image)\n",
    "    spectral_density.append(hyper[:,:,b].mean())\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "i = 0\n",
    "for image in images:\n",
    "    ax1 = fig.add_axes([0, -i * 1.1, 1, 1])\n",
    "    ax1.axis('off')\n",
    "    ax1.imshow(image)\n",
    "    i+=1\n",
    "ax1 = fig.add_axes([0, -i * 1.1 + 1, 1, 1])\n",
    "ax1.axis('off')\n",
    "ax1.text(0.5, -0.1, 'GT', ha='center', fontsize=40)\n",
    "plt.show()\n",
    "# plt.savefig(f'results/GT/000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = np.linspace(400,700,31)\n",
    "b = 0\n",
    "spectral_density = []\n",
    "for band in bands:\n",
    "    band = int(band)\n",
    "    spectral_density.append(hyper[:,:,b].mean())\n",
    "    b += 1\n",
    "plt.plot(bands, np.asarray(spectral_density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming 'rgb', 'filter', and 'hyper' are defined somewhere in your code\n",
    "\n",
    "images = []\n",
    "bands = [400, 500, 550, 700]\n",
    "b = 0\n",
    "\n",
    "images.append(rgb)\n",
    "for band in bands:\n",
    "    image = np.zeros([128, 128, 3])\n",
    "    # Assuming 'filter' and 'hyper' are defined\n",
    "    for i in range(128):\n",
    "        for j in range(128):\n",
    "            image[i, j, :] = filter[band - 360, :] * hyper[i, j, b]\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    images.append(image)\n",
    "\n",
    "# Calculate the total height of the result image including gaps\n",
    "gap_height = 10\n",
    "result_height = 128 * len(images) + gap_height * (len(images) - 1)\n",
    "\n",
    "# Create a new blank image with white background\n",
    "result_image = Image.new('RGB', (128, result_height), color='white')\n",
    "\n",
    "# Paste each individual image into the result with 10 pixels gap\n",
    "for idx, image in enumerate(images):\n",
    "    pil_image = Image.fromarray((image * 255).astype('uint8'))\n",
    "    result_image.paste(pil_image, (0, (128 + gap_height) * idx))\n",
    "\n",
    "# Add a title below the combined image\n",
    "title = \"GT\"\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(result_image)\n",
    "plt.title(title, fontsize=20, pad=10)\n",
    "plt.axis('off')\n",
    "plt.savefig('results/GT/000.png', format='PNG', bbox_inches='tight', pad_inches=0, transparent=True, dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames = {'CVAE': 'CVAE', \n",
    "                'SNCWGANres': 'SNCWGAN+ResNet', \n",
    "                'pix2pix': 'pix2pix', \n",
    "                'SNCWGANunet': 'SNCWGAN+Unet', \n",
    "                'SNCWGANdense': 'SNCWGAN+DenseNet', \n",
    "                'HSCNN_Plus': 'HSCNN_Plus', \n",
    "                'MSTPlusPlus': 'MST++', \n",
    "                'CVAESP': 'CVAE-HS', \n",
    "                'SNCWGANNoNoise': 'SNCWGAN+DT', \n",
    "                'D2GANNZ': 'D2GAN'}\n",
    "# Open and save the result image again using PIL to remove compression\n",
    "hsis = [5642,5453,5621]\n",
    "hsi = 5642\n",
    "img1 = Image.open('results/CVAE/000.png')\n",
    "\n",
    "gap_height = 20\n",
    "idx = len(modelnames) + 1\n",
    "result_width = img1.width * idx + gap_height * (idx - 1)\n",
    "result_image = Image.new('RGB', (result_width, img1.height), color='white')\n",
    "i = 0\n",
    "for k, v in modelnames.items():\n",
    "    img = Image.open(f'results/{v}/{hsi}.png')\n",
    "    result_image.paste(img, ((img1.width + gap_height) * i, 0))\n",
    "    i += 1\n",
    "    \n",
    "img = Image.open('results/GT/{hsi}.png')\n",
    "result_image.paste(img, ((img1.width + gap_height) * i, 0))\n",
    "\n",
    "result_image.save('results/{hsi}.png', format='PNG', compress_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import re\n",
    "\n",
    "spec = '/work3/s212645/Spectral_Reconstruction/FakeHyperSpectrum/CVAE/'\n",
    "f = os.listdir(spec)\n",
    "len(f)\n",
    "for i in range(len(f)):\n",
    "    num = str(i).zfill(3)\n",
    "    name = num + '.mat'\n",
    "    try:\n",
    "        with h5py.File(spec+name, 'r') as mat:\n",
    "            scipy.io.savemat(spec+name, mat)\n",
    "    except:\n",
    "        mat = scipy.io.loadmat(spec+name)\n",
    "        scipy.io.savemat(spec+name, mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "class Loss_Fid(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fid = FrechetInceptionDistance(feature=2048)\n",
    "        \n",
    "    def forward(self, outputs, label):\n",
    "        outputs = outputs * 255\n",
    "        label = label * 255\n",
    "        outputs = outputs.type(torch.ByteTensor)\n",
    "        label = label.type(torch.ByteTensor)\n",
    "        self.fid.update(label, real=True)\n",
    "        self.fid.update(outputs, real=False)\n",
    "        fidscore = self.fid.compute()\n",
    "        return fidscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(spec, 'r') as mat:\n",
    "    hyper =np.float32(np.array(mat['cube']))\n",
    "hyper = np.transpose(hyper, [2, 1, 0])\n",
    "subhyper = cv2.resize(hyper, [128, 128])\n",
    "print(subhyper.shape)\n",
    "rgb = get_rgb(subhyper, (29, 19, 9)) # fid score\n",
    "plt.imshow(rgb)\n",
    "# indices = [22, 12, 3]\n",
    "# subhyper = hyper[indices]\n",
    "# subhyper = np.transpose(subhyper, [2, 1, 0])\n",
    "# subhyper = cv2.cvtColor(subhyper, cv2.COLOR_BGR2RGB)\n",
    "# subhyper = np.float32(subhyper)\n",
    "# subhyper = (subhyper-subhyper.min())/(subhyper.max()-subhyper.min())\n",
    "# plt.imshow(subhyper)\n",
    "# view = ImageView()\n",
    "# view.set_data(hyper, (29, 19, 9)) # fid score\n",
    "# # view.set_data(hyper, (20, 13, 9)) # sam\n",
    "# plt.imshow(view.data_rgb)\n",
    "# subhyper = torch.tensor(view.data_rgb.transpose(2, 0, 1), dtype=torch.float32).to(device)\n",
    "# sam = Loss_SAM().to(device)\n",
    "# fid = Loss_Fid().to(device)\n",
    "# lossmin = 1e12\n",
    "# argi = 0\n",
    "# argj = 1\n",
    "# argk = 2\n",
    "\n",
    "# loss = fid(bgr.reshape(8, 3, 482 // 2, 512 // 4), subhyper.reshape(8, 3, 482 // 2, 512 // 4))\n",
    "# # print(subhyper)\n",
    "# for i in range(0,10):\n",
    "#     for j in range(10,20):\n",
    "#         for k in range(20, 31):\n",
    "#             view.set_data(hyper, (k, j, i))\n",
    "#             subhyper = torch.tensor(view.data_rgb.transpose(2, 0, 1), dtype=torch.float32).to(device)\n",
    "#             loss = fid(bgr.reshape(8, 3, 482 // 2, 512 // 4), subhyper.reshape(8, 3, 482 // 2, 512 // 4))\n",
    "#             if loss < lossmin:\n",
    "#                 lossmin = loss\n",
    "#                 argi = i\n",
    "#                 argj = j\n",
    "#                 argk = k\n",
    "#                 print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/work3/s212645/Spectral_Reconstruction/ICVL/data/mat/4cam_0411-1640-1.mat'\n",
    "with h5py.File(path, 'r') as mat:\n",
    "    hyper = np.float32(np.array(mat['rad']))\n",
    "    rgb = np.float32(np.array(mat['rgb']))\n",
    "hyper = np.transpose(hyper, [1, 2, 0])\n",
    "hyper = np.flip(hyper, 0)\n",
    "rgb = np.transpose(rgb, [2, 1, 0])\n",
    "rgb = np.flip(rgb, 2)\n",
    "# view = ImageView()\n",
    "rgb = get_rgb(hyper, (29, 19, 9)) # fid score\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for path, dirs, files in os.walk(ROOT+TRAIN_SP):\n",
    "    for file in files:\n",
    "        num_video = os.path.basename(path)\n",
    "        names.append(os.path.basename(os.path.dirname(path)))\n",
    "        hyper_path = os.path.join(path,file)\n",
    "        with h5py.File(hyper_path, 'r') as mat:\n",
    "            hyper =np.float32(np.array(mat['cube']))\n",
    "        hyper = np.transpose(hyper, [2, 1, 0])\n",
    "        imshow(hyper, (22, 10, 3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for path, dirs, files in os.walk(ROOT+TRAIN_RGB):\n",
    "    for file in files:\n",
    "        num_video = os.path.basename(path)\n",
    "        names.append(os.path.basename(os.path.dirname(path)))\n",
    "        hyper_path = os.path.join(path,file)\n",
    "        bgr_path = os.path.join(path,file)\n",
    "        bgr = cv2.imread(bgr_path)\n",
    "        bgr2rgb = True\n",
    "        if bgr2rgb:\n",
    "            bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "        bgr = np.float32(bgr)\n",
    "        bgr = (bgr-bgr.min())/(bgr.max()-bgr.min())\n",
    "        bgr = np.transpose(bgr, [2, 0, 1])  # [3,482,512]\n",
    "        \n",
    "        stride = 8\n",
    "        crop_size = 128\n",
    "        idx = 0\n",
    "        \n",
    "        h,w = 482,512  # img shape\n",
    "        patch_per_line = (w-crop_size)//stride+1\n",
    "        patch_per_colum = (h-crop_size)//stride+1\n",
    "        patch_per_img = patch_per_line*patch_per_colum\n",
    "        img_idx, patch_idx = idx//patch_per_img, idx%patch_per_img\n",
    "        h_idx, w_idx = patch_idx//patch_per_line, patch_idx%patch_per_line\n",
    "        img = bgr[:,h_idx*stride:h_idx*stride+crop_size, w_idx*stride:w_idx*stride+crop_size]\n",
    "        \n",
    "        img = img.transpose(1,2,0)\n",
    "        print(img.shape)\n",
    "        plt.imshow(bgr.transpose(1,2,0))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.randn([64,31,128,128])\n",
    "label = torch.randn_like(outputs)\n",
    "error = torch.abs(outputs.view(-1) - label.view(-1)) / label.view(-1)\n",
    "# mrae = torch.mean(error.reshape(-1))\n",
    "mrae = torch.mean(error.view(-1))\n",
    "mrae\n",
    "a = np.array([0,1,1])\n",
    "print(a.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "recons = torch.randn(1, 31, 128, 128)\n",
    "input = torch.randn_like(recons)\n",
    "mu = torch.randn(1, 1024)\n",
    "log_var = torch.randn_like(mu)\n",
    "\n",
    "kld_weight = 1024 / 128 / 128 / 31 # Account for the minibatch samples from the dataset\n",
    "recons_loss =F.mse_loss(recons, input)\n",
    "\n",
    "kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "print(recons_loss, kld_loss * kld_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "window_size = 4\n",
    "shift_size = 3\n",
    "H, W = 16, 16\n",
    "img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "h_slices = (slice(0, -window_size),\n",
    "            slice(-window_size, -window_size * 2),\n",
    "            slice(-window_size * 2, -window_size * 3),\n",
    "            slice(-window_size * 3, -shift_size),\n",
    "            slice(-shift_size, None))\n",
    "w_slices = (slice(0, -window_size),\n",
    "            slice(-window_size, -window_size * 2),\n",
    "            slice(-window_size * 2, -window_size * 3),\n",
    "            slice(-window_size * 3, -shift_size),\n",
    "            slice(-shift_size, None))\n",
    "cnt = 0\n",
    "for h in h_slices:\n",
    "    for w in w_slices:\n",
    "        img_mask[:, h, w, :] = cnt\n",
    "        cnt += 1\n",
    "\n",
    "mask_windows = window_partition(img_mask, window_size)  # nW, window_size, window_size, 1\n",
    "mask_windows = mask_windows.view(-1, window_size * window_size)\n",
    "\n",
    "attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "\n",
    "plt.matshow(img_mask[0, :, :, 0].numpy())\n",
    "for i in range(16):\n",
    "    plt.matshow(attn_mask[i].numpy())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = '/work3/s212645/Spectral_Reconstruction/'\n",
    "datanames = ['ICVL/', 'ARAD/', 'CAVE/']\n",
    "\n",
    "def Rename(path):\n",
    "    filelist = os.listdir(path)\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    for file in filelist:\n",
    "        if re.findall(reg, file):\n",
    "            oldname = path + file\n",
    "            number = file.split('.mat')[0]\n",
    "            newnumber = number.zfill(3)\n",
    "            newname = path + newnumber + '.mat'\n",
    "            os.rename(oldname, newname)\n",
    "\n",
    "def gen_test_list(matlist, startidx, size):\n",
    "    testlist = []\n",
    "    for i in range(size):\n",
    "        testlist.append(matlist[i + startidx])\n",
    "    return testlist\n",
    "\n",
    "def cross_validation_lists(path, test_size):\n",
    "    crossvaltrainlists = []\n",
    "    crossvaltestlists = []\n",
    "    filelist = os.listdir(path)\n",
    "    filelist.sort()\n",
    "    assert len(filelist) > test_size\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    matlist = []\n",
    "    for file in filelist:\n",
    "        if re.match(reg, file):\n",
    "            matlist.append(file)\n",
    "    matlist.sort()\n",
    "    all_length = len(matlist)\n",
    "    assert all_length % test_size == 0\n",
    "    for i in range(all_length // test_size):\n",
    "        trainlist = []\n",
    "        testlist = []\n",
    "        testlist = gen_test_list(matlist, i * test_size, test_size)\n",
    "        trainlist = matlist.copy()\n",
    "        for mat in testlist:\n",
    "            trainlist.remove(mat)\n",
    "        crossvaltestlists.append(testlist)\n",
    "        crossvaltrainlists.append(trainlist)\n",
    "    return crossvaltrainlists, crossvaltestlists\n",
    "\n",
    "def cross_validation_dataset(path, test_size, imsize):\n",
    "    train_sets = []\n",
    "    test_sets = []\n",
    "    crossvaltrainlists, crossvaltestlists = cross_validation_lists(path, test_size)\n",
    "    num_crossval = len(crossvaltrainlists)\n",
    "    for i in range(num_crossval):\n",
    "        train_sets.append(get_dataset(crossvaltrainlists[i], imsize))\n",
    "        test_sets.append(get_dataset(crossvaltestlists[i], imsize))\n",
    "    return train_sets, test_sets\n",
    "\n",
    "def get_dataset(list, imsize):\n",
    "    specs, rgbs = get_all_mats(list, imsize)\n",
    "    return specs, rgbs\n",
    "\n",
    "def split_train_test(path, test_size, imsize):\n",
    "    filelist = os.listdir(path)\n",
    "    filelist.sort()\n",
    "    assert len(filelist) > test_size\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    matlist = []\n",
    "    for file in filelist:\n",
    "        if re.match(reg, file):\n",
    "            matlist.append(file)\n",
    "    all_length = len(matlist)\n",
    "    train_size = all_length - test_size\n",
    "    matlist.sort()\n",
    "    trainlist = []\n",
    "    testlist = []\n",
    "    for i in range(train_size):\n",
    "        trainlist.append(matlist[i])\n",
    "    for j in range(test_size):\n",
    "        testlist.append(matlist[j + train_size])\n",
    "    train_sets = get_dataset(trainlist, imsize)\n",
    "    test_sets = get_dataset(testlist, imsize)\n",
    "    return train_sets, test_sets\n",
    "\n",
    "def get_all_mats(filelist, imsize):\n",
    "    specs = []\n",
    "    rgbs = []\n",
    "    for file in filelist:\n",
    "        mat = scipy.io.loadmat(path+file)\n",
    "        spec, rgb = get_all_patches(mat, imsize)\n",
    "        specs += spec\n",
    "        rgbs += rgb\n",
    "        break\n",
    "    return specs, rgbs\n",
    "    \n",
    "def Resize(hyper, rgb, h, w):\n",
    "    hyper_s = cv2.resize(hyper, [h, w])\n",
    "    rgb_s = cv2.resize(rgb, [h, w])\n",
    "    return hyper_s, rgb_s\n",
    "\n",
    "def data_resize(mat, imsize):\n",
    "    spectral_images = []\n",
    "    rgb_images = []\n",
    "    hyper = np.float32(np.array(mat['cube']))\n",
    "    rgb = np.float32(np.array(mat['rgb']))\n",
    "    h = rgb.shape[0]\n",
    "    w = rgb.shape[1]\n",
    "    while min(h // imsize, w // imsize) >= 1:\n",
    "        hyper_s, rgb_s = Resize(hyper, rgb, h, w)\n",
    "        spectral_images.append(hyper_s)\n",
    "        rgb_images.append(rgb_s)\n",
    "        h = h // 2\n",
    "        w = w // 2\n",
    "    if h > imsize / 2 or w > imsize / 2 :\n",
    "        hyper_s, rgb_s = Resize(hyper, rgb, imsize, imsize)\n",
    "        spectral_images.append(hyper_s)\n",
    "        rgb_images.append(rgb_s)\n",
    "    return spectral_images, rgb_images\n",
    "\n",
    "def patch_gen(array, imsize, h, w):\n",
    "    return array[h-imsize:h, w-imsize:w, :]\n",
    "\n",
    "def patch_image(array, imsize):\n",
    "    h = array.shape[0]\n",
    "    w = array.shape[1]\n",
    "    assert h >= imsize\n",
    "    assert w >= imsize\n",
    "    iter_h = int(np.ceil(h / imsize) + 1)\n",
    "    iter_w = int(np.ceil(w / imsize) + 1)\n",
    "    patches = []\n",
    "    for i in range(1, iter_h):\n",
    "        for j in range(1, iter_w):\n",
    "            patches.append(patch_gen(array, imsize, min(h, i * imsize), min(w, j * imsize)))\n",
    "    return patches\n",
    "    \n",
    "def get_all_patches(mat, imsize):\n",
    "    spectrals = []\n",
    "    rgbs = []\n",
    "    resize_spectrals, resize_rgbs = data_resize(mat, imsize)\n",
    "    for i in range(len(resize_spectrals)):\n",
    "        hyperpatches = patch_image(resize_spectrals[i], imsize)\n",
    "        rgbpatches = patch_image(resize_rgbs[i], imsize)\n",
    "        spectrals += hyperpatches\n",
    "        rgbs += rgbpatches\n",
    "    return spectrals, rgbs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = root + datanames[0]\n",
    "    # spectral_images, rgb_images = get_all_mats(path, 128)\n",
    "    # print(len(rgb_images))\n",
    "    # print(rgb_images[-1].shape)\n",
    "    train_sets, test_sets = split_train_test(path, 1, 128)\n",
    "    print(len(train_sets[0]))\n",
    "    print(sys.getsizeof(train_sets))\n",
    "    plt.imshow(train_sets[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import TrainDataset, ValidDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "root = '/work3/s212645/Spectral_Reconstruction/'\n",
    "datanames = ['ICVL/']\n",
    "# datanames = ['ICVL/', 'ARAD/', 'CAVE/']\n",
    "trainset = ValidDataset(root, 128, 0.02)\n",
    "print(len(trainset))\n",
    "train_loader = DataLoader(dataset=trainset, batch_size=1, shuffle=False, num_workers=2, drop_last=False)\n",
    "\n",
    "for i, (image, label) in enumerate(train_loader):\n",
    "    image = image.squeeze(0)\n",
    "    image = image.permute([1,2,0])\n",
    "    print(image.shape)\n",
    "    plt.imshow(image.cpu().numpy())\n",
    "    plt.imshow(image.cpu().numpy())\n",
    "    image = image.reshape(-1).cpu().numpy()\n",
    "    print(np.max(image), np.min(image))\n",
    "    label = label.reshape(-1).cpu().numpy()\n",
    "    print(np.max(label), np.min(label))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def SAM(s1, s2):\n",
    "    b,c,h,w = s1.shape\n",
    "    num_pix = h * w * c / 31\n",
    "    s1 = s1.reshape(-1)\n",
    "    s2 = s2.reshape(-1)\n",
    "    try:\n",
    "        s1_norm = torch.sqrt(torch.dot(s1, s1))\n",
    "        s2_norm = torch.sqrt(torch.dot(s2, s2))\n",
    "        sum_s1_s2 = torch.dot(s1, s2)\n",
    "        angle = torch.acos(sum_s1_s2 / (s1_norm * s2_norm)) / num_pix\n",
    "    except ValueError:\n",
    "        # python math don't like when acos is called with\n",
    "        # a value very near to 1\n",
    "        return 0.0\n",
    "    return angle\n",
    "\n",
    "\n",
    "def SID(s1, s2):\n",
    "    b = s1.shape[0]\n",
    "    s1 = s1.view(b, -1)\n",
    "    s2 = s2.view(b, -1)\n",
    "    s1 = nn.Sigmoid()(s1)\n",
    "    s2 = nn.Sigmoid()(s2)\n",
    "    p = (s1 / torch.sum(s1)) + torch.finfo(torch.float).eps\n",
    "    q = (s2 / torch.sum(s2)) + torch.finfo(torch.float).eps\n",
    "    return torch.mean(torch.sum(p * torch.log(p / q) + q * torch.log(q / p), dim=1).view(-1))\n",
    "\n",
    "# s1 = np.random.normal(0, 1, [128,128,31])\n",
    "# s2 = np.random.normal(0, 1, [128,128,31])\n",
    "s1 = torch.randn([2, 31, 128, 128])\n",
    "s2 = torch.randn([2, 31, 128, 128])\n",
    "# s1 = nn.Tanh()(s1)\n",
    "# s2 = nn.Tanh()(s2)\n",
    "# s2 = s1 * 0.2\n",
    "sam = SAM(s1, s2)\n",
    "sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "import os\n",
    "import re\n",
    "imgpath = '/work3/s212645/Spectral_Reconstruction/ICVL/'\n",
    "\n",
    "def Rename(path):\n",
    "    i = 1\n",
    "    filelist = os.listdir(path)\n",
    "    reg = re.compile(r'.*.mat')\n",
    "    for file in filelist:\n",
    "        if re.findall(reg, file):\n",
    "            oldname = path + file\n",
    "            # number = file.split('.mat')[0]\n",
    "            number = str(i)\n",
    "            newnumber = number.zfill(3)\n",
    "            i += 1 \n",
    "            newname = path + newnumber + '.mat'\n",
    "            os.rename(oldname, newname)\n",
    "\n",
    "Rename(imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import h5py\n",
    "import scipy.io\n",
    "specpath = '/work3/s212645/Spectral_Reconstruction/Train_Spec/'\n",
    "rgbpath = '/work3/s212645/Spectral_Reconstruction/Train_RGB/'\n",
    "\n",
    "savepath = '/work3/s212645/Spectral_Reconstruction/ARAD/'\n",
    "allname = 'ARAD_1K_'\n",
    "for i in range(950):\n",
    "    i = i + 1\n",
    "    mat = {}\n",
    "    number = str(i).zfill(4)\n",
    "    specname = allname + number + '.mat'\n",
    "    rgbname = allname + number + '.jpg'\n",
    "    hyper_path = specpath + specname\n",
    "    with h5py.File(hyper_path, 'r') as MAT:\n",
    "        hyper =np.float32(np.array(MAT['cube']))\n",
    "    mat['cube'] = np.transpose(hyper, [1, 2, 0])\n",
    "    bgr = cv2.imread(rgbpath + rgbname)\n",
    "    bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    bgr = np.float32(bgr)\n",
    "    bgr = (bgr-bgr.min())/(bgr.max()-bgr.min())\n",
    "    # bgr = np.transpose(bgr, [2, 0, 1])  # [3,482,512]\n",
    "    mat['rgb'] = bgr\n",
    "    newname = str(i).zfill(3) + '.mat'\n",
    "    scipy.io.savemat(savepath+newname, mat)\n",
    "    print(savepath+newname, ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import h5py\n",
    "import scipy.io\n",
    "\n",
    "savepath = '/work3/s212645/Spectral_Reconstruction/ARAD/'\n",
    "# matname = '/work3/s212645/Spectral_Reconstruction/ARAD_1K_0027.mat'\n",
    "# jpgname = '/work3/s212645/Spectral_Reconstruction/ARAD_1K_0027.jpg'\n",
    "# mat = {}\n",
    "# with h5py.File(matname, 'r') as MAT:\n",
    "#     hyper =np.float32(np.array(MAT['cube']))\n",
    "# mat['cube'] = np.transpose(hyper, [1,2,0])\n",
    "# print(mat['cube'].shape)\n",
    "# bgr = cv2.imread(jpgname)\n",
    "# bgr = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "# bgr = np.float32(bgr)\n",
    "# bgr = (bgr-bgr.min())/(bgr.max()-bgr.min())\n",
    "# mat['rgb'] = bgr\n",
    "# newname = str(27).zfill(3) + '.mat'\n",
    "# scipy.io.savemat(savepath+newname, mat)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(950):\n",
    "    j = i + 1\n",
    "    mat = {}\n",
    "    number = str(j).zfill(3)\n",
    "    specname = number + '.mat'\n",
    "    hyper_path = savepath + specname\n",
    "    mat = scipy.io.loadmat(hyper_path)\n",
    "    hyper =np.float32(np.array(mat['cube']))\n",
    "    mat['cube'] = np.transpose(hyper, [1,0,2])\n",
    "    print(mat['cube'].shape)\n",
    "    newname = str(j).zfill(3) + '.mat'\n",
    "    scipy.io.savemat(savepath+newname, mat)\n",
    "    print(savepath+newname, ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 26\n",
    "j = i + 1\n",
    "mat = {}\n",
    "number = str(j).zfill(3)\n",
    "specname = number + '.mat'\n",
    "hyper_path = savepath + specname\n",
    "mat = scipy.io.loadmat(hyper_path)\n",
    "hyper =np.float32(np.array(mat['cube']))\n",
    "mat['cube'] = np.transpose(hyper, [1,0,2])\n",
    "print(mat['cube'].shape)\n",
    "newname = str(j).zfill(3) + '.mat'\n",
    "scipy.io.savemat(savepath+newname, mat)\n",
    "print(savepath+newname, ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "savepath = '/work3/s212645/Spectral_Reconstruction/ARAD/'\n",
    "for i in range(950):\n",
    "    i = i + 1\n",
    "    mat = {}\n",
    "    number = str(i).zfill(3)\n",
    "    specname = number + '.mat'\n",
    "    hyper_path = savepath + specname\n",
    "    mat = scipy.io.loadmat(hyper_path)\n",
    "    hyper =np.float32(np.array(mat['cube']))\n",
    "    if np.min(hyper) < 0:\n",
    "        print('find data error at ', number)\n",
    "        print(np.min(hyper), np.max(hyper))\n",
    "        hyper = (hyper - np.min(hyper)) / (np.max(hyper) - np.min(hyper))\n",
    "        mat['cube'] = hyper\n",
    "        newname = str(i).zfill(3) + '.mat'\n",
    "        scipy.io.savemat(savepath+newname, mat)\n",
    "        print(savepath+newname, ' saved')\n",
    "    if np.max(hyper) > 1:\n",
    "        print('find data error at ', number)\n",
    "        print(np.min(hyper), np.max(hyper))\n",
    "        hyper = (hyper - np.min(hyper)) / (np.max(hyper) - np.min(hyper))\n",
    "        mat['cube'] = hyper\n",
    "        newname = str(i).zfill(3) + '.mat'\n",
    "        scipy.io.savemat(savepath+newname, mat)\n",
    "        print(savepath+newname, ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import h5py\n",
    "specpath = '/work3/s212645/Spectral_Reconstruction/ICVL/'\n",
    "\n",
    "savepath = '/work3/s212645/Spectral_Reconstruction/ICVL_Norm/'\n",
    "for i in range(201):\n",
    "    i = i + 1\n",
    "    mat = {}\n",
    "    number = str(i).zfill(3)\n",
    "    specname = number + '.mat'\n",
    "    hyper_path = specpath + specname\n",
    "    # with h5py.File(hyper_path, 'r') as MAT:\n",
    "    #     hyper =np.float32(np.array(MAT['cube']))\n",
    "    mat = scipy.io.loadmat(hyper_path)\n",
    "    hyper = mat['cube']\n",
    "    hyper = np.float32(hyper)\n",
    "    hyper = (hyper-hyper.min())/(hyper.max()-hyper.min())\n",
    "    mat['cube'] = hyper\n",
    "    print(mat['cube'].shape)\n",
    "    print(mat['rgb'].shape)\n",
    "    newname = str(i).zfill(3) + '.mat'\n",
    "    scipy.io.savemat(savepath+newname, mat)\n",
    "    print(savepath+newname, ' saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from spectral import *\n",
    "specpath = '/work3/s212645/Spectral_Reconstruction/ARAD/'\n",
    "\n",
    "# specpath = '/work3/s212645/Spectral_Reconstruction/ICVL_Norm/'\n",
    "\n",
    "i = 900\n",
    "number = str(i).zfill(3)\n",
    "specname = number + '.mat'\n",
    "hyper_path = specpath + specname\n",
    "mat = scipy.io.loadmat(hyper_path)\n",
    "hyper = mat['cube']\n",
    "rgb = mat['rgb']\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb = get_rgb(hyper, (29, 19, 9))\n",
    "plt.imshow(rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
